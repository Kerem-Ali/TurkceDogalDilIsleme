{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JNHkeiOasHwA",
    "outputId": "acf638a4-91ae-4848-8350-50542573dccb"
   },
   "outputs": [],
   "source": [
    "!pip install torch torchtext torchcrf pytorch-crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pDb6ErnwV1Cd",
    "outputId": "9efa037b-c0b5-41f8-b577-5aae48f285b8"
   },
   "outputs": [],
   "source": [
    "#!pip install datasets==2.0.1\n",
    "from datasets import load_dataset, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gCIP6_BYx7_b",
    "outputId": "a2f0a12f-b2d1-4a69-9079-9d469a61f576"
   },
   "outputs": [],
   "source": [
    "!pip install neattext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hSG8EPKiTCzc",
    "outputId": "e16cb30d-52fe-4c21-aa1f-f32c82e3fe03"
   },
   "outputs": [],
   "source": [
    "pip install pytorch-crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "amUVgu_lOMfi",
    "outputId": "686151b1-b3aa-49f8-ea7a-bdf009fa8ceb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
      "        num_rows: 20000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "\n",
    "# Later, load the dataset from disk\n",
    "dataset = load_dataset(\"wikiann\", \"tr\")\n",
    "\n",
    "# Verify that the dataset is loaded correctly\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lTS_RJ54ayLA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ai9a70Zga0-L",
    "outputId": "7bc2cfa2-9dd3-4783-9acd-19d814b39121"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['3.lük', 'maçında', 'Slovenya', 'Millî', 'Basketbol', \"Takımı'nı\", 'yendikleri', 'maçta', '23', 'sayı', ',', '6', 'ribaund', ',', '2', 'blok', 'istatistikleriyle', 'oynamış', 've', '12', 'faul', 'yaptırmıştır', '.'], 'ner_tags': [0, 0, 3, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'langs': ['tr', 'tr', 'tr', 'tr', 'tr', 'tr', 'tr', 'tr', 'tr', 'tr', 'tr', 'tr', 'tr', 'tr', 'tr', 'tr', 'tr', 'tr', 'tr', 'tr', 'tr', 'tr', 'tr'], 'spans': [\"ORG: Slovenya Millî Basketbol Takımı'nı\"]}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2B4pRotWajDD"
   },
   "outputs": [],
   "source": [
    "ner_encoding = {0: \"O\", 1: \"entity\", 2: \"entity\", 3: \"entity\", 4: \"entity\", 5: \"entity\", 6: \"entity\"}\n",
    "\n",
    "\n",
    "train_tokens = []\n",
    "train_tags = []\n",
    "for sample in dataset[\"train\"]:\n",
    "  train_tokens.append(' '.join(sample[\"tokens\"]))\n",
    "  train_tags.append(' '.join([ner_encoding[a] for a in sample[\"ner_tags\"]]))\n",
    "\n",
    "test_tokens = []\n",
    "test_tags = []\n",
    "for sample in dataset[\"train\"]:\n",
    "  test_tokens.append(' '.join(sample[\"tokens\"]))\n",
    "  test_tags.append(' '.join([ner_encoding[a] for a in sample[\"ner_tags\"]]))\n",
    "\n",
    "df_train = pd.DataFrame({\"sentence\": train_tokens, \"tags\": train_tags})\n",
    "df_test = pd.DataFrame({\"sentence\": test_tokens, \"tags\": test_tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AoePlS1jaoOy"
   },
   "outputs": [],
   "source": [
    "ner_encoding = {0: \"O\", 1: \"entity\", 2: \"entity\", 3: \"entity\", 4: \"entity\", 5: \"entity\", 6: \"entity\"}\n",
    "\n",
    "texts = []\n",
    "for sample in dataset[\"train\"]:\n",
    "  texts.append(' '.join(sample[\"tokens\"]))\n",
    "for sample in dataset[\"test\"]:\n",
    "  texts.append(' '.join(sample[\"tokens\"]))\n",
    "\n",
    "labels = []\n",
    "for sample in dataset[\"train\"]:\n",
    "  labels.append([ner_encoding[a] for a in sample[\"ner_tags\"]])\n",
    "for sample in dataset[\"test\"]:\n",
    "  labels.append([ner_encoding[a] for a in sample[\"ner_tags\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MvgUxhRoaoRI",
    "outputId": "81ff1f04-2de4-414a-aa01-01e708c3365a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "drVUSyDiaoTf"
   },
   "outputs": [],
   "source": [
    "pip install TorchCRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WeI6BMRRaoWG"
   },
   "outputs": [],
   "source": [
    "pip install torchcrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vf-KZjeJaoYK"
   },
   "outputs": [],
   "source": [
    "from TorchCRF import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torchcrf import CRF\n",
    "\n",
    "# Define NERDataset class\n",
    "class NERDataset(Dataset):\n",
    "    def __init__(self, texts, labels, vocab, tag_to_idx):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.tag_to_idx = tag_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = [self.vocab.get(word, self.vocab['<UNK>']) for word in self.texts[idx].split()]\n",
    "        labels = [self.tag_to_idx[tag] for tag in self.labels[idx]]\n",
    "        return torch.tensor(text, dtype=torch.long), torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "# Define BiLSTM_CRF model class\n",
    "class BiLSTM_CRF(nn.Module):\n",
    "    def __init__(self, vocab_size, tag_to_idx, embedding_dim=200, hidden_dim=256):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_idx = tag_to_idx\n",
    "        self.tagset_size = len(tag_to_idx)\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2, num_layers=2, bidirectional=True, dropout=0.5)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
    "        self.crf = CRF(self.tagset_size, batch_first=True)\n",
    "\n",
    "    def forward(self, sentence, tags=None):\n",
    "        embedded = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        tag_scores = self.hidden2tag(lstm_out)\n",
    "\n",
    "        if tags is not None:\n",
    "            mask = (sentence != 0).bool()\n",
    "            loss = -self.crf(tag_scores, tags, mask=mask)\n",
    "            return loss\n",
    "        else:\n",
    "            best_tags = self.crf.decode(tag_scores)\n",
    "            return best_tags\n",
    "\n",
    "# Prepare data\n",
    "def prepare_data(texts, labels):\n",
    "    vocab = {'<PAD>': 0, '<UNK>': 1}\n",
    "    tag_to_idx = {'O': 0, 'entity': 1}\n",
    "\n",
    "    for text in texts:\n",
    "        for word in text.split():\n",
    "            if word not in vocab:\n",
    "                vocab[word] = len(vocab)\n",
    "\n",
    "    return vocab, tag_to_idx\n",
    "\n",
    "# Collate function for DataLoader\n",
    "def collate_fn(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    max_len = max(len(x) for x in texts)\n",
    "    padded_texts = [torch.cat([x, torch.zeros(max_len - len(x), dtype=torch.long)]) for x in texts]\n",
    "    padded_labels = [torch.cat([y, torch.zeros(max_len - len(y), dtype=torch.long)]) for y in labels]\n",
    "    return torch.stack(padded_texts), torch.stack(padded_labels)\n",
    "\n",
    "# Example data (texts and labels should be extended with more diverse data)\n",
    "\n",
    "\n",
    "# Check and align lengths of texts and labels\n",
    "for i in range(len(texts)):\n",
    "    text_length = len(texts[i].split())\n",
    "    label_length = len(labels[i])\n",
    "    if text_length != label_length:\n",
    "        raise ValueError(f\"Text and label lengths do not match at index {i}: {text_length} != {label_length}\")\n",
    "\n",
    "# Prepare vocabulary and tag_to_idx\n",
    "vocab, tag_to_idx = prepare_data(texts, labels)\n",
    "dataset = NERDataset(texts, labels, vocab, tag_to_idx)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# Initialize model, optimizer, and device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BiLSTM_CRF(len(vocab), tag_to_idx, embedding_dim=400, hidden_dim=512).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)  # Adjusted learning rate\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3000\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for inputs, targets in dataloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(inputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "# Test sentence\n",
    "test_sentence = \"benim şirketim kazanacaktır, onun adı da turkcell\"\n",
    "test_tensor = torch.tensor([vocab.get(word, vocab['<UNK>']) for word in test_sentence.split()], dtype=torch.long).to(device)\n",
    "with torch.no_grad():\n",
    "    best_tags = model(test_tensor.unsqueeze(0))[0]\n",
    "\n",
    "idx_to_tag = {i: tag for tag, i in tag_to_idx.items()}\n",
    "predicted_labels = [idx_to_tag[i] for i in best_tags]\n",
    "print(\"Test cümlesi:\", test_sentence)\n",
    "print(\"Tahmin edilen etiketler:\", predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.81 GiB of which 13.62 MiB is free. Process 49743 has 1.60 GiB memory in use. Process 51315 has 634.00 MiB memory in use. Process 54215 has 788.00 MiB memory in use. Including non-PyTorch memory, this process has 806.00 MiB memory in use. Of the allocated memory 676.51 MiB is allocated by PyTorch, and 15.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 99\u001b[0m\n\u001b[1;32m     97\u001b[0m     loss \u001b[38;5;241m=\u001b[39m model(inputs, targets)\n\u001b[1;32m     98\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 99\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloader)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/venv/lib/python3.12/site-packages/torch/optim/optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m             )\n\u001b[0;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.12/site-packages/torch/optim/optimizer.py:89\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/venv/lib/python3.12/site-packages/torch/optim/adam.py:216\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    213\u001b[0m     state_steps: List[Tensor] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    214\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 216\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_group\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m     adam(\n\u001b[1;32m    227\u001b[0m         params_with_grad,\n\u001b[1;32m    228\u001b[0m         grads,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    246\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    247\u001b[0m     )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/venv/lib/python3.12/site-packages/torch/optim/adam.py:156\u001b[0m, in \u001b[0;36mAdam._init_group\u001b[0;34m(self, group, params_with_grad, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps)\u001b[0m\n\u001b[1;32m    146\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    147\u001b[0m     torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m    148\u001b[0m         (),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m_get_scalar_dtype())\n\u001b[1;32m    154\u001b[0m )\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# Exponential moving average of gradient values\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp_avg\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreserve_format\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# Exponential moving average of squared gradient values\u001b[39;00m\n\u001b[1;32m    160\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp_avg_sq\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(\n\u001b[1;32m    161\u001b[0m     p, memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format\n\u001b[1;32m    162\u001b[0m )\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.81 GiB of which 13.62 MiB is free. Process 49743 has 1.60 GiB memory in use. Process 51315 has 634.00 MiB memory in use. Process 54215 has 788.00 MiB memory in use. Including non-PyTorch memory, this process has 806.00 MiB memory in use. Of the allocated memory 676.51 MiB is allocated by PyTorch, and 15.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torchcrf import CRF\n",
    "\n",
    "# Define NERDataset class\n",
    "class NERDataset(Dataset):\n",
    "    def __init__(self, texts, labels, vocab, tag_to_idx):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.tag_to_idx = tag_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = [self.vocab.get(word, self.vocab['<UNK>']) for word in self.texts[idx].split()]\n",
    "        labels = [self.tag_to_idx[tag] for tag in self.labels[idx]]\n",
    "        return torch.tensor(text, dtype=torch.long), torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "# Define BiLSTM_CRF model class\n",
    "class BiLSTM_CRF(nn.Module):\n",
    "    def __init__(self, vocab_size, tag_to_idx, embedding_dim=200, hidden_dim=256):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_idx = tag_to_idx\n",
    "        self.tagset_size = len(tag_to_idx)\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2, num_layers=2, bidirectional=True, dropout=0.5)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
    "        self.crf = CRF(self.tagset_size, batch_first=True)\n",
    "\n",
    "    def forward(self, sentence, tags=None):\n",
    "        embedded = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        tag_scores = self.hidden2tag(lstm_out)\n",
    "\n",
    "        if tags is not None:\n",
    "            mask = (sentence != 0).bool()\n",
    "            loss = -self.crf(tag_scores, tags, mask=mask)\n",
    "            return loss\n",
    "        else:\n",
    "            best_tags = self.crf.decode(tag_scores)\n",
    "            return best_tags\n",
    "\n",
    "# Prepare data\n",
    "def prepare_data(texts, labels):\n",
    "    vocab = {'<PAD>': 0, '<UNK>': 1}\n",
    "    tag_to_idx = {'O': 0, 'entity': 1}\n",
    "\n",
    "    for text in texts:\n",
    "        for word in text.split():\n",
    "            if word not in vocab:\n",
    "                vocab[word] = len(vocab)\n",
    "\n",
    "    return vocab, tag_to_idx\n",
    "\n",
    "# Collate function for DataLoader\n",
    "def collate_fn(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    max_len = max(len(x) for x in texts)\n",
    "    padded_texts = [torch.cat([x, torch.zeros(max_len - len(x), dtype=torch.long)]) for x in texts]\n",
    "    padded_labels = [torch.cat([y, torch.zeros(max_len - len(y), dtype=torch.long)]) for y in labels]\n",
    "    return torch.stack(padded_texts), torch.stack(padded_labels)\n",
    "\n",
    "# Example data (texts and labels should be extended with more diverse data)\n",
    "\n",
    "\n",
    "# Check and align lengths of texts and labels\n",
    "for i in range(len(texts)):\n",
    "    text_length = len(texts[i].split())\n",
    "    label_length = len(labels[i])\n",
    "    if text_length != label_length:\n",
    "        raise ValueError(f\"Text and label lengths do not match at index {i}: {text_length} != {label_length}\")\n",
    "\n",
    "# Prepare vocabulary and tag_to_idx\n",
    "vocab, tag_to_idx = prepare_data(texts, labels)\n",
    "dataset = NERDataset(texts, labels, vocab, tag_to_idx)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# Initialize model, optimizer, and device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BiLSTM_CRF(len(vocab), tag_to_idx, embedding_dim=800, hidden_dim=1024).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)  # Adjusted learning rate\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3000\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for inputs, targets in dataloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(inputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "# Test sentence\n",
    "test_sentence = \"benim şirketim kazanacaktır, onun adı da turkcell\"\n",
    "test_tensor = torch.tensor([vocab.get(word, vocab['<UNK>']) for word in test_sentence.split()], dtype=torch.long).to(device)\n",
    "with torch.no_grad():\n",
    "    best_tags = model(test_tensor.unsqueeze(0))[0]\n",
    "\n",
    "idx_to_tag = {i: tag for tag, i in tag_to_idx.items()}\n",
    "predicted_labels = [idx_to_tag[i] for i in best_tags]\n",
    "print(\"Test cümlesi:\", test_sentence)\n",
    "print(\"Tahmin edilen etiketler:\", predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"Vatan Bilgisayardan cok iyi bir Türk Telekomdan daha iyi\"\n",
    "test_tensor = torch.tensor([vocab.get(word, vocab['<UNK>']) for word in test_sentence.split()], dtype=torch.long).to(device)\n",
    "with torch.no_grad():\n",
    "    best_tags = model(test_tensor.unsqueeze(0))[0]\n",
    "\n",
    "idx_to_tag = {i: tag for tag, i in tag_to_idx.items()}\n",
    "predicted_labels = [idx_to_tag[i] for i in best_tags]\n",
    "print(\"Test cümlesi:\", test_sentence)\n",
    "print(\"Tahmin edilen etiketler:\", predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"bugün mediamarkt mağazasından iphone 7 plus satın aldım ama sorunlu çıktı\"\n",
    "test_tensor = torch.tensor([vocab.get(word, vocab['<UNK>']) for word in test_sentence.split()], dtype=torch.long).to(device)\n",
    "with torch.no_grad():\n",
    "    best_tags = model(test_tensor.unsqueeze(0))[0]\n",
    "\n",
    "idx_to_tag = {i: tag for tag, i in tag_to_idx.items()}\n",
    "predicted_labels = [idx_to_tag[i] for i in best_tags]\n",
    "print(\"Test cümlesi:\", test_sentence)\n",
    "print(\"Tahmin edilen etiketler:\", predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#pickle.dump(model,open(\"entity_cikarici.ai2\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = pickle.load(open(\"entity_cikarici.ai\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"bugün mediamarkt mağazasından iphone 7 plus satın aldım ama sorunlu çıktı\"\n",
    "test_tensor = torch.tensor([vocab.get(word, vocab['<UNK>']) for word in test_sentence.split()], dtype=torch.long).to(device)\n",
    "with torch.no_grad():\n",
    "    best_tags = model2(test_tensor.unsqueeze(0))[0]\n",
    "\n",
    "idx_to_tag = {i: tag for tag, i in tag_to_idx.items()}\n",
    "predicted_labels = [idx_to_tag[i] for i in best_tags]\n",
    "print(\"Test cümlesi:\", test_sentence)\n",
    "print(\"Tahmin edilen etiketler:\", predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install zemberek-python;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
